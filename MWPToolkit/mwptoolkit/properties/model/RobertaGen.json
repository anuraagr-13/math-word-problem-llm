{
    "pretrained_model":"roberta-base",
    "embedding_size": 768,
    "ffn_size": 1024,
    "num_decoder_layers": 2,
    "num_heads": 8,
    "embedding_dropout_ratio": 0.5,
    "attn_dropout_ratio": 0.5,
    "attn_weight_dropout_ratio": 0.5,
    "ffn_dropout_ratio": 0.5,
    "learning_rate": 0.00001,
    "warmup_steps": 1500,
    "beam_size": 5,
    "learner": "schedule",
    "decoding_strategy": "greedy_search",
    "share_vocab":false,
    "symbol_for_tree":false,
    "mask_symbol":"number",
    "max_len":128,
    "epoch_nums":200,
    "teacher_force_ratio":0.9,
    "add_sos":true,
    "add_eos":true,
    "train_batch_size":8,
    "test_batch_size":8,
    "add_num_symbol": true,
    "embedding": "roberta"
}